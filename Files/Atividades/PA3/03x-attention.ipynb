{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UuW5SwnBoO3m"
   },
   "source": [
    "# Mecanismos de Atenção"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i-qwx1LvoQ7C"
   },
   "source": [
    "## 1 Atenção causal e bidirecional"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Durante a aula você aprendeu sobre o mencanismo de atenção usado nos modelos de linguagem atuais. Criamos a classe `SelfAttention_v2` com atenção bidirecional, onde cada token pode dar atenção tanto para os tokens que vem antes na sentença, como pode dar atenção para os tokens subsequentes. Em seguida, adicionamos causalidade na atenção e criamos a classe `CausalAttention`, que faz com que os tokens dêem atenção apenas para os tokens passados, comumente usada nos grandes modelos de linguagem generativos.\n",
    "\n",
    "Porém, modelos como o T5 usam a arquitetura enconder-decoder, que mistura os dois tipos de atenção: bidirecional (nos enconders) e causal (nos decoders). Tendo isso em mente, faça o seguinte:\n",
    "\n",
    "- Baseando-se na classe `CausalAttention`, crie a classe `SelfAttention_v3` que poderá se comportar tanto com atenção bidirecional quanto com atenção causal. Para isso, adicione o parâmetro booleano `is_causal` no construtor da classe, que aplicará o filtro causal na matriz de atenção caso o parâmetro seja verdadeiro e bidirecional caso seja falso. Altere também o retorno do método forward para retornar tanto o `context_vec`quanto o `attn_weights`.\n",
    "\n",
    "- Em seguida passe o input definido abaixo pela pela nova classe `SelfAttention_v3` usando a arquitetura bidirecional e também a arquitetura causal e imprima o resultado dos vetores de contexto e dos pesos de atenção nas duas situações para comparar a diferença entre eles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yfkoPZw7d5Ly"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "inputs = torch.tensor(\n",
    "  [[[0.43, 0.15, 0.89], # Your     (x^1)\n",
    "   [0.55, 0.87, 0.66], # journey  (x^2)\n",
    "   [0.57, 0.85, 0.64], # starts   (x^3)\n",
    "   [0.22, 0.58, 0.33], # with     (x^4)\n",
    "   [0.77, 0.25, 0.10], # one      (x^5)\n",
    "   [0.05, 0.80, 0.55]]] # step     (x^6)\n",
    ")\n",
    "\n",
    "d_in, d_out = 3, 2\n",
    "context_length=6\n",
    "dropout=0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SpfhAXXzZ8D8"
   },
   "outputs": [],
   "source": [
    "class SelfAttention_v3(nn.Module):\n",
    "    def __init__(self, ): # COMPLETE OS PARÂMETROS\n",
    "        super().__init__()\n",
    "        # SEU CÓDIGO\n",
    "\n",
    "    def forward(self, ): # COMPLETE OS PARÂMETROS\n",
    "        # SEU CÓDIGO\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VKSzsL4BhK5K"
   },
   "outputs": [],
   "source": [
    "# PASSE O INPUT PELA SelfAttention_v3 COM O PARÂMETRO is_causal=True\n",
    "# E IMPRIMA A MATRIZ DE ATENÇÃO RETORNADA\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8MFiKw3WeYV8"
   },
   "outputs": [],
   "source": [
    "# PASSE O INPUT PELA SelfAttention_v3 COM O PARÂMETRO is_causal=false\n",
    "# E IMPRIMA A MATRIZ DE ATENÇÃO RETORNADA\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kDjTMkCAcO85"
   },
   "source": [
    "## 2 Multi-head Attention + Data Loading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use o data loader visto nas aulas anteriores para tokenizar e processar o texto abaixo para a tarefa de previsão do próximo token e passe o primeiro batch de dados pela camada de multi-head attention visto na aula passada e imprima o shape da saída. Lembre-se que os tokens gerados pelo data loader devem passar pela camada de token embeddings e position embeddings (token_embedding + position_embedding) antes de passar pela atenção. Essas camadas também já foram definidas abaixo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yW10IkTGkuZY"
   },
   "outputs": [],
   "source": [
    "import tiktoken\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "\n",
    "time_machine_text = \"The Time Traveller (for so it will be convenient to speak of him) \\\n",
    "was expounding a recondite matter to us. His grey eyes shone and \\\n",
    "twinkled, and his usually pale face was flushed and animated. The \\\n",
    "fire burned brightly, and the soft radiance of the incandescent \\\n",
    "lights in the lilies of silver caught the bubbles that flashed and \\\n",
    "passed in our glasses. Our chairs, being his patents, embraced and \\\n",
    "caressed us rather than submitted to be sat upon, and there was that \\\n",
    "luxurious after-dinner atmosphere when thought roams gracefully \\\n",
    "free of the trammels of precision. And he put it to us in this \\\n",
    "way--marking the points with a lean forefinger--as we sat and lazily \\\n",
    "admired his earnestness over this new paradox (as we thought it) \\\n",
    "and his fecundity.\"\n",
    "\n",
    "\n",
    "vocab_size = 50257\n",
    "emb_dim = 256\n",
    "context_length = 1024\n",
    "\n",
    "\n",
    "token_embedding_layer = nn.Embedding(vocab_size, emb_dim)\n",
    "pos_embedding_layer = nn.Embedding(context_length, emb_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TvWsArfqk1Sc"
   },
   "outputs": [],
   "source": [
    "# DEFINA A CLASSE DE DATASET, O DATA LOADER E A CLASSE DE MULTI HEAD ATTENTION\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "N3Mp4KV2qSAE"
   },
   "outputs": [],
   "source": [
    "# CARREGUE O DATA LOADER COM O TEXTO ACIMA\n",
    "# PASSE O PRIMEIRO BATCH PELA CAMADA DE EMBEDDING\n",
    "# PASSE O EMBEDDING PELA MULTI HEAD ATTENTION\n",
    "# IMPRIMA O SHAPE DA SAÍDA\n",
    "\n",
    "max_length = 4\n",
    "batch_size = 8\n",
    "stride = 4\n",
    "context_length = 4\n",
    "num_heads = 2\n",
    "d_in = emb_dim\n",
    "d_out = emb_dim\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyPDakiOaiykI6XRWO+JjQYX",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
