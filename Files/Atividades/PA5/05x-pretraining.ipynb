{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4i7BKL1r1uCf"
   },
   "source": [
    "# Pré-Treinamento"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WBPK6t88RT6H"
   },
   "source": [
    "## 1. Entropia antes e depois do pré-treino\n",
    "Na aula passada você aprendeu a preparar os dados e fazer o pré-treino do modelo usando dados não rotulados. Vamos colocar isto em prática com novos dados e vamos medir o impacto do pré-treinamento. Compute a entropia do capítulo 6 do livro _The Time Machine_ com o modelo GPT sem nenhum pré-treinamento. Depois faça o pré-treino do modelo usando os cinco primeiros capítulos do mesmo livro e em seguida volte a computar a entropia do capítulo 6. Para isso, faça o seguinte:\n",
    "\n",
    "- Recrie as classes para o modelo GPT e as funções do data loader.\n",
    "- Instancie o GPTModel com 124M de parâmetros.\n",
    "- Passe o texto do capítulo 6 pelo modelo e compute a entropia.\n",
    "- Faça o pré-treino do modelo usando os 5 primeiros capítulos.\n",
    "- Passe novamente o texto do capítulo 6 pelo modelo pré-treinado e compute a entropia e veja a diferença.\n",
    "\n",
    "Execute a célula logo abaixo para fazer o download dos arquivos. Um arquivo contém o texto dos 5 primeiros capítulos do livro que você usará para o pré-treinamento e o outro arquivo possui o texto do capítulo 6 que você usará para computar a entropia. O conteúdo dos arquivos é armazenado nas variáveis `time_machine_ch01_ch05` e `time_machine_ch06`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NHWEkkjVVhIx"
   },
   "source": [
    "#### Download dos arquivos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hqLDc0751sZ-"
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import re\n",
    "\n",
    "def download_file_from_google_drive(file_url, destination):\n",
    "    file_id = extract_google_drive_id(file_url)\n",
    "    URL = \"https://docs.google.com/uc?export=download&confirm=1\"\n",
    "\n",
    "    session = requests.Session()\n",
    "\n",
    "    response = session.get(URL, params={\"id\": file_id}, stream=True)\n",
    "    token = get_confirm_token(response)\n",
    "\n",
    "    if token:\n",
    "        params = {\"id\": file_id, \"confirm\": token}\n",
    "        response = session.get(URL, params=params, stream=True)\n",
    "\n",
    "    save_response_content(response, destination)\n",
    "\n",
    "\n",
    "def extract_google_drive_id(url):\n",
    "    url_pattern = r\"/d/([a-zA-Z0-9_-]+)/view\\?\"\n",
    "    response = re.search(url_pattern, url)\n",
    "    if response:\n",
    "        return response.group(1)\n",
    "    return None\n",
    "\n",
    "\n",
    "def get_confirm_token(response):\n",
    "    for key, value in response.cookies.items():\n",
    "        if key.startswith(\"download_warning\"):\n",
    "            return value\n",
    "\n",
    "    return None\n",
    "\n",
    "\n",
    "def save_response_content(response, destination):\n",
    "    CHUNK_SIZE = 32768\n",
    "\n",
    "    with open(destination, \"wb\") as f:\n",
    "        for chunk in response.iter_content(CHUNK_SIZE):\n",
    "            if chunk:  # filter out keep-alive new chunks\n",
    "                f.write(chunk)\n",
    "\n",
    "\n",
    "# download dos arquivos\n",
    "url_time_machine_ch01_ch05 = \"https://drive.google.com/file/d/1nFeGmveao-WxYt5eAGjTnln2JUu4ugCr/view?usp=sharing\"\n",
    "download_file_from_google_drive(url_time_machine_ch01_ch05, \"The Time Machine - ch01 to ch05.txt\")\n",
    "\n",
    "url_time_machine_ch06 = \"https://drive.google.com/file/d/16q2ftm6B9wRBO4hhUEUSH8uU-6RgKdxy/view?usp=sharing\"\n",
    "download_file_from_google_drive(url_time_machine_ch06, \"The Time Machine - ch06.txt\")\n",
    "\n",
    "# carrega o conteúdo dos arquivos nas variáveis\n",
    "with open(\"The Time Machine - ch01 to ch05.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "    time_machine_ch01_ch05 = f.read()\n",
    "\n",
    "with open(\"The Time Machine - ch06.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "    time_machine_ch06 = f.read()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DMmcMwKvVqnF"
   },
   "source": [
    "#### Imports\n",
    "Os imports necessários já estão todos aqui"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "frTMJxnr-io0"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import urllib\n",
    "import tiktoken\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gKtYJg3cV968"
   },
   "source": [
    "#### Dataset e dataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yDZfU31K-cKb"
   },
   "outputs": [],
   "source": [
    "# RECRIE AS CLASSES DO DATASET E DATALOADER\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MB4qwo6EWwNI"
   },
   "source": [
    "#### GPTModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kPjHxt9hdnzf"
   },
   "outputs": [],
   "source": [
    "# RECRIE AS CLASSES PARA CRIAÇÃO DO MODELO GPT\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z-pcNiQzW8GM"
   },
   "source": [
    "#### Funções de treinamento e avaliação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "voXvPYOZl8s6"
   },
   "outputs": [],
   "source": [
    "# RECRIE AS FUNÇÕES PARA O TREINAMENTO DO MODELO, VISTAS NA ÚLTIMA AULA\n",
    "# train_model_simple E FUNÇÕES RELACIONADAS\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IyR_m9SOXucn"
   },
   "source": [
    "#### Instanciação do GPT 124M e tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YklMzs-SoZL-"
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "GPT_CONFIG_124M = {\n",
    "    \"vocab_size\": 50257,   # Vocabulary size\n",
    "    \"context_length\": 256, # Shortened context length (orig: 1024)\n",
    "    \"emb_dim\": 768,        # Embedding dimension\n",
    "    \"n_heads\": 12,         # Number of attention heads\n",
    "    \"n_layers\": 12,        # Number of layers\n",
    "    \"drop_rate\": 0.1,      # Dropout rate\n",
    "    \"qkv_bias\": False      # Query-key-value bias\n",
    "}\n",
    "\n",
    "# INSTANCIE O GPT PASSANDO A CONFIGURAÇÃO ACIMA\n",
    "# INSTANCIE TAMBÉM O TOKENIZER TIKTOKEN USANDO O GPT2 ENCONDING\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oTZz7DHGVcrN"
   },
   "source": [
    "#### Entropia com o modelo sem nenhum pré-treino"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bUd5D2zF99LI"
   },
   "outputs": [],
   "source": [
    "# CARREGE O CAPÍTULO 6 NO DATA LOADER E COMPUTE A ENTROPIA (A LOSS USADA NO TREINO)\n",
    "# PASSANDO O TEXTO PELO MODELO SEM TREINAMENTO\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5PDHhutBVPyw"
   },
   "source": [
    "#### Pré-treino com os capítulos 1 a 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Muqa5oAZBhAJ"
   },
   "outputs": [],
   "source": [
    "# Dados de treino e validção\n",
    "train_ratio = 0.90\n",
    "split_idx = int(train_ratio * len(time_machine_ch01_ch05))\n",
    "train_data = time_machine_ch01_ch05[:split_idx]\n",
    "val_data = time_machine_ch01_ch05[split_idx:]\n",
    "\n",
    "# parâmetros de treinamento\n",
    "num_epochs = 10\n",
    "eval_freq = 5\n",
    "eval_iter = 5\n",
    "start_context = \"The Time Machine.\"\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=0.0004, weight_decay=0.1)\n",
    "\n",
    "\n",
    "# CRIE OS DATA LOADERS PARA OS DADOS DE TREINO E VALIDAÇÃO DEFINIDOS ACIMA\n",
    "# EM SEGUIDA, CHAME A FUNÇÃO DE TREINO PASSANDO OS PARÂMETROS DEFINIDOS ACIMA\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8fuLXJG3U_eZ"
   },
   "source": [
    "#### Entropia do capítulo 6 após o pré-treino com os capítulos 1 a 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oOjEbCkxLzV1"
   },
   "outputs": [],
   "source": [
    "# PASSE NOVAMENTE O CAPÍTULO 6 PELO MODELO, AGORA PRÉ-TREINADO E COMPUTE A\n",
    "# ENTROPIA NOVAMENTE E VEJA A DIFERENÇA\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RN1mej6pVyvT"
   },
   "source": [
    "## 2. Entropia com pesos do Hugging Face\n",
    "Crie uma nova instância do modelo GPT a partir dos pesos pré-treinados no Hugging Face e calcule novamente a entropia do texto do capítulo 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pc8rQGD_V2Q-"
   },
   "outputs": [],
   "source": [
    "file_name = \"gpt2-small-124M.pth\"\n",
    "url = f\"https://huggingface.co/rasbt/gpt2-from-scratch-pytorch/resolve/main/{file_name}\"\n",
    "\n",
    "if not os.path.exists(file_name):\n",
    "    urllib.request.urlretrieve(url, file_name)\n",
    "    print(f\"Downloaded to {file_name}\")\n",
    "\n",
    "BASE_CONFIG = {\n",
    "    \"vocab_size\": 50257,    # Vocabulary size\n",
    "    \"context_length\": 1024, # Context length\n",
    "    \"drop_rate\": 0.0,       # Dropout rate\n",
    "    \"qkv_bias\": True,        # Query-key-value bias\n",
    "    \"emb_dim\": 768,\n",
    "    \"n_layers\": 12,\n",
    "    \"n_heads\": 12\n",
    "}\n",
    "\n",
    "# INSTANCIE O MODELO GPT COM A BASE_CONFIG DEFINIDA ACIMA\n",
    "# (USE A MESMA CLASSE QUE VC DEFINIU NO INÍCIO DESTE NOTEBOOK)\n",
    "# E CARREGUE OS PESOS A PARTIR DO ARQUIVO BAIXADO PELO COMANDO ACIMA\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tpOYrQsVYrpM"
   },
   "outputs": [],
   "source": [
    "# CRIE O DATA LOADER COM O TEXTO DO CAPÍTULO 6, PASSE PELO MODELO E COMPUTE A\n",
    "# ENTROPIA\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyPY0EM4aa26BLh3SLxdy06t",
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
