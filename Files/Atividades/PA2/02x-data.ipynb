{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mn62ZgDN7qNd"
   },
   "source": [
    "# Preparação de Dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MqBWP0GW2Jk4"
   },
   "source": [
    "## 1 Byte pair encoding de palavras fora do voculário\n",
    "\n",
    "Durante a aula vimos que um tokenizador baseado em Byte pair encoding (BPE) é capaz de lidar com palavras fora do vocabulário ao dividir uma palavra em \"sub-palavras\" que estejam presentes no vocabulário. Na pior das hipóteses a palavra pode ser quebrada em letras individuais.\n",
    "\n",
    "O texto abaixo é um trecho tirado do primeiro parágrafo do livro \"The Time Machine\" (H. G. Wells, 1895). Use o Tiktoken (com encoding do gpt2) visto durante a aula para tokenizá-lo e verifique quais palavras não estão presentes no vocabulário e necessitaram ser quebradas em \"sub-palavras\". Mostre como ficou a divisão de cada uma das palavras originalmente fora do vocabulário após a tokenização.\n",
    "\n",
    "Por exemplo, a palavra \"luxurious\":<br>\n",
    "`luxurious -> ['lux', 'urious']`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 34,
     "status": "ok",
     "timestamp": 1750281188636,
     "user": {
      "displayName": "Rafael Glater",
      "userId": "13807686656890524906"
     },
     "user_tz": 180
    },
    "id": "1CXUaNqfuvSr"
   },
   "outputs": [],
   "source": [
    "time_machine_text = 'The Time Traveller was expounding a recondite matter to us. \\\n",
    "His grey eyes shone and twinkled, and his usually pale face was flushed and animated.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 548,
     "status": "ok",
     "timestamp": 1750281190734,
     "user": {
      "displayName": "Rafael Glater",
      "userId": "13807686656890524906"
     },
     "user_tz": 180
    },
    "id": "6TTFQ_-op__c",
    "outputId": "fa382b7c-aabc-4452-f29d-ad29bd4b9df9"
   },
   "outputs": [],
   "source": [
    "import tiktoken\n",
    "\n",
    "# SEU CÓDIGO AQUI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gIr_d1CI8H8v"
   },
   "source": [
    "## 2 Data loader com diferentes tamanhos de contexto e strides\n",
    "\n",
    "Durante a aula, vimos como criar um data loader pra treinar uma LLM através da tarefa de prever o próximo token. No caso, o input `x` é uma sequência de tokens e o alvo `y` é o próximo token da sequência `x`. O data loader cria uma janela deslizante que percorre todo o texto, gerando inúmeros exemplos de treino `x, y`. A quantidade de dados de treino gerada pelo data loader vai variar de acordo com o tamanho de `x` (`max_length`) e o tanto que a janela irá deslizar (`stride`) ao longo do texto.\n",
    "\n",
    "Use o data loader visto durante a aula para tokenizar o texto abaixo com duas configurações distintas:\n",
    "- `batch_size=4, max_length=2, stride=1`\n",
    "- `batch_size=4, max_length=6, stride=2`\n",
    "\n",
    "E responda, quantos exemplos de treino cada configuração o data loader gerou? Lembre-se que cada batch pode conter até 4 exemplos de treino."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 41,
     "status": "ok",
     "timestamp": 1750283362465,
     "user": {
      "displayName": "Rafael Glater",
      "userId": "13807686656890524906"
     },
     "user_tz": 180
    },
    "id": "0cSwpsUVAyiY"
   },
   "outputs": [],
   "source": [
    "time_machine_text = \"The Time Traveller (for so it will be convenient to speak of him) \\\n",
    "was expounding a recondite matter to us. His grey eyes shone and \\\n",
    "twinkled, and his usually pale face was flushed and animated. The \\\n",
    "fire burned brightly, and the soft radiance of the incandescent \\\n",
    "lights in the lilies of silver caught the bubbles that flashed and \\\n",
    "passed in our glasses. Our chairs, being his patents, embraced and \\\n",
    "caressed us rather than submitted to be sat upon, and there was that \\\n",
    "luxurious after-dinner atmosphere when thought roams gracefully \\\n",
    "free of the trammels of precision. And he put it to us in this \\\n",
    "way--marking the points with a lean forefinger--as we sat and lazily \\\n",
    "admired his earnestness over this new paradox (as we thought it) \\\n",
    "and his fecundity.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 6339,
     "status": "ok",
     "timestamp": 1750283442438,
     "user": {
      "displayName": "Rafael Glater",
      "userId": "13807686656890524906"
     },
     "user_tz": 180
    },
    "id": "xQm82iBRBMUM"
   },
   "outputs": [],
   "source": [
    "import tiktoken\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "# SEU CÓDIGO COM A CLASSE DO DATASET E A FUNÇÃO DO DATA LOADER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 25,
     "status": "ok",
     "timestamp": 1750283623598,
     "user": {
      "displayName": "Rafael Glater",
      "userId": "13807686656890524906"
     },
     "user_tz": 180
    },
    "id": "v8Qj6jRVBccZ",
    "outputId": "db0daea2-b60e-44a5-b57d-175534084c6d"
   },
   "outputs": [],
   "source": [
    "# CHAME O DATA LOADER COM TEXTO ACIMA COM A 1ª CONFIGURAÇÃO\n",
    "# E CONTE OS EXEMPLOS DE TREINO\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 18,
     "status": "ok",
     "timestamp": 1750283651730,
     "user": {
      "displayName": "Rafael Glater",
      "userId": "13807686656890524906"
     },
     "user_tz": 180
    },
    "id": "i6j0G9dcCOK4",
    "outputId": "a07bb269-12ce-47e9-dd22-4db88737972a"
   },
   "outputs": [],
   "source": [
    "# CHAME O DATA LOADER COM TEXTO ACIMA COM A 2ª CONFIGURAÇÃO\n",
    "# E CONTE OS EXEMPLOS DE TREINO\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyP2pZUkQiOJdPzwIUzIXjs7",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
